This assignment focuses on various prompting methods and how they can affect an LLM's output. By comparing the responses of two LLM's, Chat-GPT (GPT-4) and Google Gemini, based on various prompt-methods (chain-of-thought, zero-shot, few-shot, self-consistency, and prompt-chaining), we can see how prompting methods can have a significant effect. In this assignment, a short analysis and comparison was done for 22 different tasks, which can be found in Report.pdf . The AI model's outputs were condensed and only the important aspects were extracted in the report to save space - to access the raw data, please look in RawData.pdf .